{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84fe51b2",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c8ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install roboflow pillow matplotlib seaborn tqdm numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the git repository with the code\n",
    "import os\n",
    "if not os.path.exists('Dice-Detection'):\n",
    "    !git clone https://github.com/Adr44mo/Dice-Detection.git\n",
    "    %cd Dice-Detection\n",
    "else:\n",
    "    %cd Dice-Detection\n",
    "\n",
    "# Add src to path\n",
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96cb5c",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a65fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Import custom modules\n",
    "from src.dataset import DiceDetectionDataset, collate_fn\n",
    "from src.model import get_fasterrcnn_model, save_model_checkpoint\n",
    "from src.training import train_one_epoch, evaluate, get_optimizer, get_lr_scheduler\n",
    "from src.metrics import evaluate_map, print_metrics\n",
    "from src.augmentation import ClassAwareSampler, MosaicAugmentation, apply_random_augmentations\n",
    "from src.visualization import (\n",
    "    plot_class_distribution,\n",
    "    plot_training_history,\n",
    "    display_sample_batch,\n",
    "    visualize_predictions,\n",
    "    plot_ap_comparison\n",
    ")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32061ba",
   "metadata": {},
   "source": [
    "## 3. Download Dataset from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c3ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "# TODO: Add your Roboflow API key\n",
    "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "# Download the dice dataset\n",
    "project = rf.workspace(\"workspace-spezm\").project(\"dice-0sexk\")\n",
    "dataset = project.version(1).download(\"coco\")\n",
    "\n",
    "print(f\"Dataset downloaded to: {dataset.location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c9a222",
   "metadata": {},
   "source": [
    "## 4. Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset paths\n",
    "DATASET_PATH = dataset.location\n",
    "TRAIN_PATH = os.path.join(DATASET_PATH, \"train\")\n",
    "VAL_PATH = os.path.join(DATASET_PATH, \"valid\")\n",
    "TEST_PATH = os.path.join(DATASET_PATH, \"test\")\n",
    "\n",
    "# Check if test set exists\n",
    "has_test_set = os.path.exists(TEST_PATH) and os.path.exists(os.path.join(TEST_PATH, \"_annotations.coco.json\"))\n",
    "print(f\"Test set available: {has_test_set}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = DiceDetectionDataset(\n",
    "    root_dir=TRAIN_PATH,\n",
    "    annotation_file=\"_annotations.coco.json\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "val_dataset = DiceDetectionDataset(\n",
    "    root_dir=VAL_PATH,\n",
    "    annotation_file=\"_annotations.coco.json\",\n",
    "    split=\"val\"\n",
    ")\n",
    "\n",
    "# Create test dataset if available\n",
    "if has_test_set:\n",
    "    test_dataset = DiceDetectionDataset(\n",
    "        root_dir=TEST_PATH,\n",
    "        annotation_file=\"_annotations.coco.json\",\n",
    "        split=\"test\"\n",
    "    )\n",
    "    print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "else:\n",
    "    test_dataset = None\n",
    "    print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "    print(f\"No test set - will use validation set for final evaluation\")\n",
    "\n",
    "print(f\"Number of classes: {train_dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e65e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "train_distribution = train_dataset.get_class_distribution()\n",
    "print(\"Training set class distribution:\")\n",
    "for class_name, count in sorted(train_distribution.items()):\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "\n",
    "plot_class_distribution(train_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fda747",
   "metadata": {},
   "source": [
    "## 5. Setup Class-Aware Sampling\n",
    "\n",
    "Class-aware sampling ensures that each class appears roughly equally during training, regardless of the original class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fe31cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 2\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.005\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Augmentation settings\n",
    "USE_CLASS_AWARE_SAMPLING = True\n",
    "USE_MOSAIC_AUGMENTATION = True\n",
    "MOSAIC_PROB = 0.5\n",
    "\n",
    "print(f\"Training on: {DEVICE}\")\n",
    "print(f\"Class-aware sampling: {USE_CLASS_AWARE_SAMPLING}\")\n",
    "print(f\"Mosaic augmentation: {USE_MOSAIC_AUGMENTATION} (prob={MOSAIC_PROB})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e98201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class-aware sampler\n",
    "if USE_CLASS_AWARE_SAMPLING:\n",
    "    train_sampler = ClassAwareSampler(\n",
    "        train_dataset,\n",
    "        samples_per_epoch=len(train_dataset) * 2,  # Sample more to see each class\n",
    "        balance_by='dice_value'\n",
    "    )\n",
    "    shuffle = False  # Don't shuffle when using custom sampler\n",
    "    print(f\"Using class-aware sampler with {len(train_sampler)} samples per epoch\")\n",
    "else:\n",
    "    train_sampler = None\n",
    "    shuffle = True\n",
    "    print(\"Using standard random sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72df52e4",
   "metadata": {},
   "source": [
    "## 6. Wrapper Dataset for Mosaic Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Wrapper dataset that applies mosaic augmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dataset, use_mosaic=True, mosaic_prob=0.5):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.use_mosaic = use_mosaic\n",
    "        \n",
    "        if use_mosaic:\n",
    "            self.mosaic = MosaicAugmentation(\n",
    "                base_dataset,\n",
    "                output_size=(640, 640),\n",
    "                prob=mosaic_prob\n",
    "            )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.use_mosaic:\n",
    "            image, target = self.mosaic(idx)\n",
    "        else:\n",
    "            image, target = self.base_dataset[idx]\n",
    "        \n",
    "        # Apply random augmentations\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            from torchvision.transforms import functional as F\n",
    "            image = F.to_pil_image(image)\n",
    "        \n",
    "        image, target = apply_random_augmentations(image, target)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        from torchvision.transforms import ToTensor\n",
    "        image = ToTensor()(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# Create augmented training dataset\n",
    "augmented_train_dataset = AugmentedDataset(\n",
    "    train_dataset,\n",
    "    use_mosaic=USE_MOSAIC_AUGMENTATION,\n",
    "    mosaic_prob=MOSAIC_PROB\n",
    ")\n",
    "\n",
    "print(f\"Created augmented training dataset with {len(augmented_train_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb289a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize mosaic augmentation examples\n",
    "if USE_MOSAIC_AUGMENTATION:\n",
    "    print(\"Examples of Mosaic Augmentation:\\n\")\n",
    "    display_sample_batch(\n",
    "        augmented_train_dataset,\n",
    "        num_samples=4,\n",
    "        class_names=train_dataset.categories\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52886bc",
   "metadata": {},
   "source": [
    "## 7. Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59bc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = data.DataLoader(\n",
    "    augmented_train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=shuffle,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abe9976",
   "metadata": {},
   "source": [
    "## 8. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb15e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = get_fasterrcnn_model(\n",
    "    num_classes=train_dataset.num_classes,\n",
    "    pretrained=True,\n",
    "    trainable_backbone_layers=3\n",
    ")\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Setup optimizer and scheduler\n",
    "optimizer = get_optimizer(model, lr=LEARNING_RATE)\n",
    "lr_scheduler = get_lr_scheduler(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "print(f\"Model initialized on {DEVICE}\")\n",
    "print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"Initial learning rate: {optimizer.param_groups[0]['lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34919111",
   "metadata": {},
   "source": [
    "## 9. Training Loop with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "CHECKPOINT_DIR = \"checkpoints_augmented\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Starting training with augmentation...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train\n",
    "    train_metrics = train_one_epoch(\n",
    "        model, optimizer, train_loader, DEVICE, epoch + 1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_metrics = evaluate(model, val_loader, DEVICE)\n",
    "    \n",
    "    # Update learning rate\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_metrics['loss'])\n",
    "    history['val_loss'].append(val_metrics['val_loss'])\n",
    "    history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "    print(f\"  Train Loss: {train_metrics['loss']:.4f}\")\n",
    "    print(f\"  Val Loss: {val_metrics['val_loss']:.4f}\")\n",
    "    print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    print(f\"  Time: {train_metrics['time']:.2f}s\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_metrics['val_loss'] < best_val_loss:\n",
    "        best_val_loss = val_metrics['val_loss']\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_DIR, \"best_model_augmented.pth\")\n",
    "        save_model_checkpoint(\n",
    "            model, optimizer, epoch + 1, val_metrics['val_loss'],\n",
    "            checkpoint_path,\n",
    "            additional_info={\n",
    "                'train_loss': train_metrics['loss'],\n",
    "                'use_class_aware_sampling': USE_CLASS_AWARE_SAMPLING,\n",
    "                'use_mosaic_augmentation': USE_MOSAIC_AUGMENTATION\n",
    "            }\n",
    "        )\n",
    "        print(f\"  ✓ New best model saved!\")\n",
    "    \n",
    "    # Save latest checkpoint\n",
    "    latest_path = os.path.join(CHECKPOINT_DIR, \"latest_model_augmented.pth\")\n",
    "    save_model_checkpoint(\n",
    "        model, optimizer, epoch + 1, val_metrics['val_loss'],\n",
    "        latest_path\n",
    "    )\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training completed!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb43e15",
   "metadata": {},
   "source": [
    "## 10. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b92f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history({\n",
    "    'Training Loss': history['train_loss'],\n",
    "    'Validation Loss': history['val_loss'],\n",
    "    'Learning Rate': history['learning_rate']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122963f7",
   "metadata": {},
   "source": [
    "## 11. Final Evaluation with mAP\n",
    "\n",
    "Note: Using test set if available, otherwise validation set for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare evaluation dataset and loader\n",
    "# Use test set if available, otherwise use validation set\n",
    "eval_dataset = test_dataset if has_test_set else val_dataset\n",
    "eval_loader = data.DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Evaluating on: {'Test' if has_test_set else 'Validation'} set\")\n",
    "print(f\"Evaluation dataset size: {len(eval_dataset)}\")\n",
    "\n",
    "# Load best model for evaluation\n",
    "best_checkpoint = torch.load(os.path.join(CHECKPOINT_DIR, \"best_model_augmented.pth\"))\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "model.to(DEVICE)\n",
    "\n",
    "print(f\"Loaded best model from epoch {best_checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on evaluation set (test or validation) at multiple IoU thresholds\n",
    "print(f\"Evaluating augmented model with mAP metric on {'test' if has_test_set else 'validation'} set...\\n\")\n",
    "\n",
    "# Evaluate at multiple IoU thresholds\n",
    "iou_thresholds = [0.5, 0.75, 0.9, 1.0]\n",
    "all_map_results_augmented = {}\n",
    "\n",
    "print(\"Evaluating at multiple IoU thresholds:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for iou_thresh in iou_thresholds:\n",
    "    print(f\"\\nEvaluating at IoU threshold: {iou_thresh}\")\n",
    "    map_results = evaluate_map(\n",
    "        model, eval_loader, DEVICE,\n",
    "        iou_threshold=iou_thresh,\n",
    "        confidence_threshold=0.05\n",
    "    )\n",
    "    all_map_results_augmented[f\"mAP@{iou_thresh}\"] = map_results['mAP']\n",
    "    print(f\"mAP@{iou_thresh}: {map_results['mAP']:.4f}\")\n",
    "\n",
    "# Store detailed results for IoU=0.5 (standard metric)\n",
    "detailed_results_augmented = evaluate_map(\n",
    "    model, eval_loader, DEVICE,\n",
    "    iou_threshold=0.5,\n",
    "    confidence_threshold=0.05\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"mAP Summary at Different IoU Thresholds:\")\n",
    "print(\"=\" * 50)\n",
    "for threshold, mAP_value in all_map_results_augmented.items():\n",
    "    print(f\"{threshold}: {mAP_value:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nDetailed Results at IoU=0.5:\")\n",
    "print_metrics(detailed_results_augmented, class_names=eval_dataset.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5416931b",
   "metadata": {},
   "source": [
    "## 12. Compare with Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661be11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline results if available\n",
    "baseline_results_file = \"../baseline_results.json\"\n",
    "\n",
    "if os.path.exists(baseline_results_file):\n",
    "    with open(baseline_results_file, 'r') as f:\n",
    "        baseline_results = json.load(f)\n",
    "    \n",
    "    print(\"Comparison with Baseline:\\n\")\n",
    "    print(f\"Baseline mAP@0.5: {baseline_results['mAP@0.5']:.4f}\")\n",
    "    print(f\"Augmented mAP@0.5: {detailed_results_augmented['mAP']:.4f}\")\n",
    "    print(f\"Improvement: {(detailed_results_augmented['mAP'] - baseline_results['mAP@0.5']):.4f}\")\n",
    "    print(f\"Relative improvement: {((detailed_results_augmented['mAP'] / baseline_results['mAP@0.5']) - 1) * 100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"mAP Comparison at Different IoU Thresholds:\")\n",
    "    print(\"=\" * 50)\n",
    "    for threshold in ['mAP@0.5', 'mAP@0.75', 'mAP@0.9', 'mAP@1.0']:\n",
    "        baseline_val = baseline_results.get('mAP_at_iou_thresholds', {}).get(threshold, 'N/A')\n",
    "        augmented_val = all_map_results_augmented.get(threshold, 'N/A')\n",
    "        if baseline_val != 'N/A' and augmented_val != 'N/A':\n",
    "            print(f\"{threshold}: Baseline={baseline_val:.4f}, Augmented={augmented_val:.4f}, Diff={augmented_val-baseline_val:.4f}\")\n",
    "        else:\n",
    "            print(f\"{threshold}: Baseline={baseline_val}, Augmented={augmented_val}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Extract per-class AP for comparison (at IoU=0.5)\n",
    "    baseline_ap = {int(k.split('_')[-1]): v for k, v in baseline_results['per_class_ap'].items()}\n",
    "    augmented_ap = {int(k.split('_')[-1]): v for k, v in detailed_results_augmented.items() if k.startswith('AP_class_')}\n",
    "    \n",
    "    # Plot comparison\n",
    "    plot_ap_comparison(\n",
    "        baseline_ap,\n",
    "        augmented_ap,\n",
    "        class_names=val_dataset.categories\n",
    "    )\n",
    "else:\n",
    "    print(\"Baseline results not found. Run the baseline notebook first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d20d7a",
   "metadata": {},
   "source": [
    "## 13. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions on random evaluation samples\n",
    "model.eval()\n",
    "\n",
    "num_visualizations = 6\n",
    "indices = np.random.choice(len(eval_dataset), num_visualizations, replace=False)\n",
    "\n",
    "print(f\"Visualizing predictions from {'test' if has_test_set else 'validation'} set:\\n\")\n",
    "\n",
    "for idx in indices:\n",
    "    image, target = eval_dataset[idx]\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        prediction = model([image.to(DEVICE)])[0]\n",
    "    \n",
    "    # Visualize\n",
    "    visualize_predictions(\n",
    "        image,\n",
    "        prediction,\n",
    "        class_names=eval_dataset.categories,\n",
    "        confidence_threshold=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fbd3bb",
   "metadata": {},
   "source": [
    "## 14. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e73d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation results\n",
    "results_file = \"augmented_results.json\"\n",
    "\n",
    "results = {\n",
    "    'model': 'Faster R-CNN ResNet50-FPN (with augmentation)',\n",
    "    'evaluated_on': 'test' if has_test_set else 'validation',\n",
    "    'augmentation_techniques': {\n",
    "        'class_aware_sampling': USE_CLASS_AWARE_SAMPLING,\n",
    "        'mosaic_augmentation': USE_MOSAIC_AUGMENTATION,\n",
    "        'mosaic_prob': MOSAIC_PROB\n",
    "    },\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'best_val_loss': float(best_val_loss),\n",
    "    'final_train_loss': float(history['train_loss'][-1]),\n",
    "    'mAP@0.5': float(detailed_results_augmented['mAP']),\n",
    "    'mAP_at_iou_thresholds': {k: float(v) for k, v in all_map_results_augmented.items()},\n",
    "    'per_class_ap': {k: float(v) for k, v in detailed_results_augmented.items() if k.startswith('AP_class_')},\n",
    "    'training_history': history\n",
    "}\n",
    "\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {results_file}\")\n",
    "print(f\"Note: Model was evaluated on the {'test' if has_test_set else 'validation'} set\")\n",
    "print(f\"\\nmAP Summary:\")\n",
    "for threshold, mAP_value in all_map_results_augmented.items():\n",
    "    print(f\"  {threshold}: {mAP_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a319c60e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "### Augmentation Techniques\n",
    "1. **Class-Aware Sampling**: Balanced training by sampling images based on class distribution\n",
    "   - Ensures minority classes are seen more frequently\n",
    "   - Prevents model bias towards majority classes\n",
    "\n",
    "2. **Mosaic Augmentation**: Combined 4 images into 2×2 grids\n",
    "   - Increases diversity of object scales and contexts\n",
    "   - Improves model robustness to different arrangements\n",
    "\n",
    "### Expected Improvements\n",
    "- Better performance on minority classes\n",
    "- More robust detection across varied contexts\n",
    "- Improved overall mAP\n",
    "\n",
    "### Next Steps\n",
    "1. Fine-tune augmentation parameters (mosaic probability, sampling strategy)\n",
    "2. Experiment with additional augmentations (rotation, scaling, color jitter)\n",
    "3. Try different model architectures (MobileNet for speed)\n",
    "4. Implement the full Yahtzee web application"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
