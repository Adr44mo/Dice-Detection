{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2850ce79",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1187b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install roboflow pillow matplotlib seaborn tqdm numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a58aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the git repository with the code\n",
    "import os\n",
    "if not os.path.exists('Dice-Detection'):\n",
    "    !git clone https://github.com/Adr44mo/Dice-Detection.git\n",
    "    %cd Dice-Detection\n",
    "else:\n",
    "    %cd Dice-Detection\n",
    "\n",
    "# Add src to path\n",
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b19a5a",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2eb0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Import custom modules\n",
    "from src.dataset import DiceDetectionDataset, collate_fn\n",
    "from src.model import get_fasterrcnn_model, save_model_checkpoint, get_fasterrcnn_mobilenet\n",
    "from src.training import train_one_epoch, evaluate, get_optimizer, get_lr_scheduler\n",
    "from src.metrics import evaluate_map, print_metrics\n",
    "from src.visualization import (\n",
    "    plot_class_distribution,\n",
    "    plot_training_history,\n",
    "    display_sample_batch,\n",
    "    visualize_predictions\n",
    ")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098ccf6",
   "metadata": {},
   "source": [
    "## 3. Download Dataset from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f78134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "# TODO: Add your Roboflow API key\n",
    "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "# Download the dice dataset\n",
    "project = rf.workspace(\"workspace-spezm\").project(\"dice-0sexk\")\n",
    "dataset = project.version(2).download(\"coco\")\n",
    "\n",
    "print(f\"Dataset downloaded to: {dataset.location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1891ee23",
   "metadata": {},
   "source": [
    "## 4. Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458b28ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset paths\n",
    "DATASET_PATH = dataset.location\n",
    "TRAIN_PATH = os.path.join(DATASET_PATH, \"train\")\n",
    "VAL_PATH = os.path.join(DATASET_PATH, \"valid\")\n",
    "TEST_PATH = os.path.join(DATASET_PATH, \"test\")\n",
    "\n",
    "print(f\"Training path: {TRAIN_PATH}\")\n",
    "print(f\"Validation path: {VAL_PATH}\")\n",
    "print(f\"Test path: {TEST_PATH}\")\n",
    "\n",
    "# Check if test set exists\n",
    "has_test_set = os.path.exists(TEST_PATH) and os.path.exists(os.path.join(TEST_PATH, \"_annotations.coco.json\"))\n",
    "print(f\"\\nTest set available: {has_test_set}\")\n",
    "\n",
    "# Check annotation file\n",
    "train_ann_file = os.path.join(TRAIN_PATH, \"_annotations.coco.json\")\n",
    "with open(train_ann_file, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "print(f\"\\nNumber of training images: {len(coco_data['images'])}\")\n",
    "print(f\"Number of annotations: {len(coco_data['annotations'])}\")\n",
    "print(f\"Number of categories: {len(coco_data['categories'])}\")\n",
    "print(f\"\\nCategories: {[cat['name'] for cat in coco_data['categories']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3af9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = DiceDetectionDataset(\n",
    "    root_dir=TRAIN_PATH,\n",
    "    annotation_file=\"_annotations.coco.json\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "val_dataset = DiceDetectionDataset(\n",
    "    root_dir=VAL_PATH,\n",
    "    annotation_file=\"_annotations.coco.json\",\n",
    "    split=\"val\"\n",
    ")\n",
    "\n",
    "# Create test dataset if available\n",
    "if has_test_set:\n",
    "    test_dataset = DiceDetectionDataset(\n",
    "        root_dir=TEST_PATH,\n",
    "        annotation_file=\"_annotations.coco.json\",\n",
    "        split=\"test\"\n",
    "    )\n",
    "    print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "else:\n",
    "    test_dataset = None\n",
    "    print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "    print(f\"No test set - will use validation set for final evaluation\")\n",
    "\n",
    "print(f\"Number of classes: {train_dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c03418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "train_distribution = train_dataset.get_class_distribution()\n",
    "print(\"Training set class distribution:\")\n",
    "for class_name, count in train_distribution.items():\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "\n",
    "plot_class_distribution(train_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images\n",
    "display_sample_batch(\n",
    "    train_dataset,\n",
    "    num_samples=6,\n",
    "    class_names=train_dataset.categories\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c1656b",
   "metadata": {},
   "source": [
    "## 5. Prepare Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 2\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.005\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print(f\"Training on: {DEVICE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Number of epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a03d4",
   "metadata": {},
   "source": [
    "## 6. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = get_fasterrcnn_mobilenet(\n",
    "    num_classes=train_dataset.num_classes,\n",
    "    pretrained=True,\n",
    "    trainable_backbone_layers=3\n",
    ")\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a58cdd",
   "metadata": {},
   "source": [
    "## 7. Setup Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer and scheduler\n",
    "optimizer = get_optimizer(model, lr=LEARNING_RATE)\n",
    "lr_scheduler = get_lr_scheduler(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"Initial learning rate: {optimizer.param_groups[0]['lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256d012",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbd1cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Starting training...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163dda36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train\n",
    "    train_metrics = train_one_epoch(\n",
    "        model, optimizer, train_loader, DEVICE, epoch + 1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_metrics = evaluate(model, val_loader, DEVICE)\n",
    "    \n",
    "    # Update learning rate\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_metrics['loss'])\n",
    "    history['val_loss'].append(val_metrics['val_loss'])\n",
    "    history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "    print(f\"  Train Loss: {train_metrics['loss']:.4f}\")\n",
    "    print(f\"  Val Loss: {val_metrics['val_loss']:.4f}\")\n",
    "    print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    print(f\"  Time: {train_metrics['time']:.2f}s\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_metrics['val_loss'] < best_val_loss:\n",
    "        best_val_loss = val_metrics['val_loss']\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_DIR, \"best_model.pth\")\n",
    "        save_model_checkpoint(\n",
    "            model, optimizer, epoch + 1, val_metrics['val_loss'],\n",
    "            checkpoint_path,\n",
    "            additional_info={'train_loss': train_metrics['loss']}\n",
    "        )\n",
    "        print(f\"  âœ“ New best model saved!\")\n",
    "    \n",
    "    # Save latest checkpoint\n",
    "    latest_path = os.path.join(CHECKPOINT_DIR, \"latest_model.pth\")\n",
    "    save_model_checkpoint(\n",
    "        model, optimizer, epoch + 1, val_metrics['val_loss'],\n",
    "        latest_path\n",
    "    )\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training completed!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c15884",
   "metadata": {},
   "source": [
    "## 9. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0002f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history({\n",
    "    'Training Loss': history['train_loss'],\n",
    "    'Validation Loss': history['val_loss'],\n",
    "    'Learning Rate': history['learning_rate']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8952bb",
   "metadata": {},
   "source": [
    "## 10. Final Evaluation with mAP\n",
    "\n",
    "Note: Using test set if available, otherwise validation set for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb3f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare evaluation dataset and loader\n",
    "# Use test set if available, otherwise use validation set\n",
    "eval_dataset = test_dataset if has_test_set else val_dataset\n",
    "eval_loader = data.DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Evaluating on: {'Test' if has_test_set else 'Validation'} set\")\n",
    "print(f\"Evaluation dataset size: {len(eval_dataset)}\")\n",
    "\n",
    "# Load best model for evaluation\n",
    "best_checkpoint = torch.load(os.path.join(CHECKPOINT_DIR, \"best_model.pth\"))\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "model.to(DEVICE)\n",
    "\n",
    "print(f\"Loaded best model from epoch {best_checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on evaluation set with multiple IoU thresholds\n",
    "print(f\"Evaluating model with mAP metric on {'test' if has_test_set else 'validation'} set...\\n\")\n",
    "\n",
    "iou_thresholds = [0.5, 0.75, 0.9, 1.0]\n",
    "all_map_results = {}\n",
    "\n",
    "for iou_thresh in iou_thresholds:\n",
    "    print(f\"Computing mAP @ IoU {iou_thresh}...\")\n",
    "    map_results = evaluate_map(\n",
    "        model, eval_loader, DEVICE,\n",
    "        iou_threshold=iou_thresh,\n",
    "        confidence_threshold=0.05\n",
    "    )\n",
    "    all_map_results[f'mAP@{iou_thresh}'] = map_results['mAP']\n",
    "    \n",
    "    print(f\"  mAP@{iou_thresh}: {map_results['mAP']:.4f}\")\n",
    "    \n",
    "    # Store detailed results for IoU=0.5 (most common)\n",
    "    if iou_thresh == 0.5:\n",
    "        detailed_results = map_results\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Summary of mAP at Different IoU Thresholds:\")\n",
    "print(\"=\"*60)\n",
    "for threshold, mAP_value in all_map_results.items():\n",
    "    print(f\"  {threshold}: {mAP_value:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nDetailed per-class results (IoU=0.5):\")\n",
    "print_metrics(detailed_results, class_names=eval_dataset.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfdceb5",
   "metadata": {},
   "source": [
    "## 11. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions on random evaluation samples\n",
    "model.eval()\n",
    "\n",
    "num_visualizations = 6\n",
    "indices = np.random.choice(len(eval_dataset), num_visualizations, replace=False)\n",
    "\n",
    "print(f\"Visualizing predictions from {'test' if has_test_set else 'validation'} set:\\n\")\n",
    "\n",
    "for idx in indices:\n",
    "    image, target = eval_dataset[idx]\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        prediction = model([image.to(DEVICE)])[0]\n",
    "    \n",
    "    # Visualize\n",
    "    visualize_predictions(\n",
    "        image,\n",
    "        prediction,\n",
    "        class_names=eval_dataset.categories,\n",
    "        confidence_threshold=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb624d5",
   "metadata": {},
   "source": [
    "## 12. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83271463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation results\n",
    "results_file = \"baseline_results.json\"\n",
    "\n",
    "results = {\n",
    "    'model': 'Faster R-CNN ResNet50-FPN',\n",
    "    'evaluated_on': 'test' if has_test_set else 'validation',\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'best_val_loss': float(best_val_loss),\n",
    "    'final_train_loss': float(history['train_loss'][-1]),\n",
    "    'mAP@0.5': float(detailed_results['mAP']),\n",
    "    'mAP_at_iou_thresholds': {k: float(v) for k, v in all_map_results.items()},\n",
    "    'per_class_ap': {k: float(v) for k, v in detailed_results.items() if k.startswith('AP_class_')},\n",
    "    'training_history': history\n",
    "}\n",
    "\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {results_file}\")\n",
    "print(f\"Note: Model was evaluated on the {'test' if has_test_set else 'validation'} set\")\n",
    "print(f\"\\nmAP Summary:\")\n",
    "for threshold, mAP_value in all_map_results.items():\n",
    "    print(f\"  {threshold}: {mAP_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a282b65",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This baseline model provides:\n",
    "- Faster R-CNN with ResNet50-FPN backbone\n",
    "- Standard training without augmentation\n",
    "- Evaluation using mAP@0.5\n",
    "- Per-class performance metrics\n",
    "\n",
    "Next steps:\n",
    "1. Implement class-aware sampling in the augmentation notebook\n",
    "2. Apply mosaic augmentation\n",
    "3. Compare results with baseline"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
